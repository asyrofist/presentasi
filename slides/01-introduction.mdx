import { Appear, Embed, Notes } from 'mdx-deck'
import { CodeSurferLayout } from 'code-surfer'

##### üë®‚Äçüåæ [Tesis Pascasarjana S2 Teknik Informatika ITS](.)

Ekstraksi Kebergatungan Evolutionary Requirements antar kebutuhan dengan pemrosesan bahasa alamiah

###### Diusulkan oleh Rakha Asyrofi / 05111950010038
###### Dibimbing oleh Daniel Oranova Siahaan, S.Kom., M.Sc., PD.Eng 
###### NIP. 19741123 200604 1 001

<Notes>
Baik terima kasih, sebelumnya atas waktu bapak/ibu luangkan untuk mendengar presentasi tesis saya.
Yang berjudul Ekstraksi Kebergatungan Evolutionary Requirements antar kebutuhan dengan pemrosesan bahasa alamiah
yang disusun oleh saya sendiri Rakha Asyrofi, dengan bimbingan bapak Daniel Oranova Siahaan selaku dosen pembimbing saya
</Notes>

---

# Daftar Isi
- Latar Belakang 
- Penelitian sebelumnya
- Penggalian Ulasan Model Kebergatungan
- Metode Penelitian
- Dokumentasi dan Pengujian
  [...](https://docs.google.com/presentation/d/1e4VAUfFaBRF3XnRbdTLZm9w3-YV45a766G0QadqiEM8/edit?usp=sharing)

<Notes>
Saya mulai dari daftar isi yang akan saya sampaikan dimulai dari latar Belakang, penelitian sebelumnya,
Penggalian Ulasan model kebergantungan, metode penelitian dan dokumentasi serta pengujian yang telah dikerjakan.
</Notes>

---

<CodeSurferLayout>

```python subtitle='function untuk melakukan preprocessing'
def preprocessing(index0):
  x1 = pd.ExcelFile(index0)
  dfs = {sh:x1.parse(sh) for sh in x1.sheet_names}
  return dfs
```

```python subtitle='function untuk mengecek dataset secara full'
def fulldataset(index0, index1):
  x1 = pd.ExcelFile(index0)
  dfs = {sh:x1.parse(sh) for sh in x1.sheet_names}[index1]
  return dfs

```

```python subtitle='function untuk mengecek datase secara spesifik'
def dataset(index0, index1, index2, index3):
  x1 = pd.ExcelFile(index0)
  dfs = {sh:pd.x1.parse(sh) for sh in pd.x1.sheet_names}[index1][index2][index3]
  return dfs
```

```python subtitle='function untuk menyiapkan data ke sebuah list'
def apply_cleaning_function_to_list(X):
    cleaned_X = []
    for element in X:
        cleaned_X.append(clean_text(element))
    return cleaned_X
```

```python subtitle='function untuk membersihkan data'
def clean_text(raw_text):    
    text = raw_text.lower() # Convert to lower case
    tokens = nltk.word_tokenize(text) # Tokenize    
    token_words = [w for w in tokens if w.isalpha()] # Keep only words (removes punctuation + numbers)    
    lemma_words = [lem.lemmatize(w) for w in token_words] # Lemmatization
    meaningful_words = [w for w in lemma_words if not w in stops] # Remove stop words
    joined_words = ( " ".join(meaningful_words)) # Rejoin meaningful stemmed words
    return joined_words
```
  
```python subtitle='function untuk mencari similaritas'
def ukurSimilaritas(req1, req2):    
    for num in req1:
      dataSimilartas = [metodeSimilaritas(num, index) for index in req2]
      return dataSimilaritas
```

</CodeSurferLayout>
